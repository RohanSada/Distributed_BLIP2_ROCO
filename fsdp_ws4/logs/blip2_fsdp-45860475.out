[Dataset] Loaded 1960 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/train.jsonl
[Dataset] Loaded 40 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/val.jsonl
[FSDP] init on host=nid002344 | rank=0/4 | local_rank=0 | device_index=0 | MASTER_ADDR=128.55.64.209:29500 | CUDA_VISIBLE_DEVICES=0,1,2,3
[Dataset] Loaded 1960 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/train.jsonl
[Dataset] Loaded 40 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/val.jsonl
[FSDP] world_size=4, rank=0, local_rank=0, device_index=0
[FSDP] Config: FSDPConfig(model_name_or_path='/pscratch/sd/r/rs2531/Course_Project/hf_cache/blip2-flan-t5-xl', data_root='/pscratch/sd/r/rs2531/Course_Project/roco_caption/data', train_jsonl='train.jsonl', val_jsonl='val.jsonl', output_dir='/pscratch/sd/r/rs2531/Course_Project/FSDP/fsdp_ws4/checkpoints', num_epochs=5, train_batch_size=1, eval_batch_size=1, learning_rate=1e-05, weight_decay=0.01, warmup_steps=0, max_text_len=64, num_workers=4, seed=42, log_every=10, save_every=0, grad_clip=1.0, sharding_strategy='full', use_mixed_precision=True, cpu_offload=False)
[FSDP] Saved run metadata to /pscratch/sd/r/rs2531/Course_Project/FSDP/fsdp_ws4/checkpoints/run_meta.json
[Dataset] Loaded 1960 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/train.jsonl
[Dataset] Loaded 40 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/val.jsonl
[Dataset] Loaded 1960 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/train.jsonl
[Dataset] Loaded 40 samples from /pscratch/sd/r/rs2531/Course_Project/roco_caption/data/val.jsonl
[FSDP] num_train_batches_per_rank=490, num_training_steps=490
[rank0] Loading BLIP-2 model from /pscratch/sd/r/rs2531/Course_Project/hf_cache/blip2-flan-t5-xl
========== Epoch 0 ==========
[Epoch 0 Step 0/490] Loss (global avg): 24.0073
[Epoch 0 Step 10/490] Loss (global avg): 19.4066
[Epoch 0 Step 20/490] Loss (global avg): 13.2283
[Epoch 0 Step 30/490] Loss (global avg): 9.7271
[Epoch 0 Step 40/490] Loss (global avg): 7.6866
[Epoch 0 Step 50/490] Loss (global avg): 6.3258
[Epoch 0 Step 60/490] Loss (global avg): 5.3752
[Epoch 0 Step 70/490] Loss (global avg): 4.6803
[Epoch 0 Step 80/490] Loss (global avg): 4.1788
[Epoch 0 Step 90/490] Loss (global avg): 3.7656
[Epoch 0 Step 100/490] Loss (global avg): 3.4240
[Epoch 0 Step 110/490] Loss (global avg): 3.1380
[Epoch 0 Step 120/490] Loss (global avg): 2.9087
[Epoch 0 Step 130/490] Loss (global avg): 2.7105
[Epoch 0 Step 140/490] Loss (global avg): 2.5317
[Epoch 0 Step 150/490] Loss (global avg): 2.3818
[Epoch 0 Step 160/490] Loss (global avg): 2.2456
[Epoch 0 Step 170/490] Loss (global avg): 2.1321
[Epoch 0 Step 180/490] Loss (global avg): 2.0269
[Epoch 0 Step 190/490] Loss (global avg): 1.9293
[Epoch 0 Step 200/490] Loss (global avg): 1.8405
[Epoch 0 Step 210/490] Loss (global avg): 1.7593
[Epoch 0 Step 220/490] Loss (global avg): 1.6863
[Epoch 0 Step 230/490] Loss (global avg): 1.6174
[Epoch 0 Step 240/490] Loss (global avg): 1.5560
[Epoch 0 Step 250/490] Loss (global avg): 1.4991
[Epoch 0 Step 260/490] Loss (global avg): 1.4456
[Epoch 0 Step 270/490] Loss (global avg): 1.3977
[Epoch 0 Step 280/490] Loss (global avg): 1.3529
[Epoch 0 Step 290/490] Loss (global avg): 1.3101
[Epoch 0 Step 300/490] Loss (global avg): 1.2705
[Epoch 0 Step 310/490] Loss (global avg): 1.2318
[Epoch 0 Step 320/490] Loss (global avg): 1.1975
[Epoch 0 Step 330/490] Loss (global avg): 1.1642
[Epoch 0 Step 340/490] Loss (global avg): 1.1333
[Epoch 0 Step 350/490] Loss (global avg): 1.1038
[Epoch 0 Step 360/490] Loss (global avg): 1.0755
[Epoch 0 Step 370/490] Loss (global avg): 1.0488
[Epoch 0 Step 380/490] Loss (global avg): 1.0246
[Epoch 0 Step 390/490] Loss (global avg): 1.0010
[Epoch 0 Step 400/490] Loss (global avg): 0.9785
[Epoch 0 Step 410/490] Loss (global avg): 0.9568
[Epoch 0 Step 420/490] Loss (global avg): 0.9361
[Epoch 0 Step 430/490] Loss (global avg): 0.9159
[Epoch 0 Step 440/490] Loss (global avg): 0.8970
[Epoch 0 Step 450/490] Loss (global avg): 0.8804
[Epoch 0 Step 460/490] Loss (global avg): 0.8643
[Epoch 0 Step 470/490] Loss (global avg): 0.8482
[Epoch 0 Step 480/490] Loss (global avg): 0.8327
[Eval] Loss (global avg): 0.1099
[Epoch 0] train_loss=0.8186, val_loss=0.1099, epoch_time=735.9s, time/step=1.5018s, samples/s_per_gpu=0.7, samples/s_global=2.7, peak_mem_gb_rank0=33.28
[FSDP] Logged epoch metrics to /pscratch/sd/r/rs2531/Course_Project/FSDP/fsdp_ws4/checkpoints/metrics_epoch.jsonl
========== Epoch 1 ==========
[Epoch 1 Step 0/490] Loss (global avg): 0.1108
[Epoch 1 Step 10/490] Loss (global avg): 0.1007
[Epoch 1 Step 20/490] Loss (global avg): 0.0960
[Epoch 1 Step 30/490] Loss (global avg): 0.0874
[Epoch 1 Step 40/490] Loss (global avg): 0.0890
[Epoch 1 Step 50/490] Loss (global avg): 0.0847
[Epoch 1 Step 60/490] Loss (global avg): 0.0799
[Epoch 1 Step 70/490] Loss (global avg): 0.0794
[Epoch 1 Step 80/490] Loss (global avg): 0.0774
[Epoch 1 Step 90/490] Loss (global avg): 0.0768
[Epoch 1 Step 100/490] Loss (global avg): 0.0775
[Epoch 1 Step 110/490] Loss (global avg): 0.0813
[Epoch 1 Step 120/490] Loss (global avg): 0.0854
[Epoch 1 Step 130/490] Loss (global avg): 0.0890
[Epoch 1 Step 140/490] Loss (global avg): 0.0872
[Epoch 1 Step 150/490] Loss (global avg): 0.0858
[Epoch 1 Step 160/490] Loss (global avg): 0.0857
[Epoch 1 Step 170/490] Loss (global avg): 0.0839
[Epoch 1 Step 180/490] Loss (global avg): 0.0844
[Epoch 1 Step 190/490] Loss (global avg): 0.0834
[Epoch 1 Step 200/490] Loss (global avg): 0.0819
[Epoch 1 Step 210/490] Loss (global avg): 0.0811
[Epoch 1 Step 220/490] Loss (global avg): 0.0800
[Epoch 1 Step 230/490] Loss (global avg): 0.0805
[Epoch 1 Step 240/490] Loss (global avg): 0.0801
[Epoch 1 Step 250/490] Loss (global avg): 0.0790
[Epoch 1 Step 260/490] Loss (global avg): 0.0791
[Epoch 1 Step 270/490] Loss (global avg): 0.0782
[Epoch 1 Step 280/490] Loss (global avg): 0.0777
[Epoch 1 Step 290/490] Loss (global avg): 0.0773
[Epoch 1 Step 300/490] Loss (global avg): 0.0776
[Epoch 1 Step 310/490] Loss (global avg): 0.0772
[Epoch 1 Step 320/490] Loss (global avg): 0.0769
[Epoch 1 Step 330/490] Loss (global avg): 0.0762
[Epoch 1 Step 340/490] Loss (global avg): 0.0757
[Epoch 1 Step 350/490] Loss (global avg): 0.0752
[Epoch 1 Step 360/490] Loss (global avg): 0.0746
[Epoch 1 Step 370/490] Loss (global avg): 0.0740
[Epoch 1 Step 380/490] Loss (global avg): 0.0731
[Epoch 1 Step 390/490] Loss (global avg): 0.0727
[Epoch 1 Step 400/490] Loss (global avg): 0.0726
[Epoch 1 Step 410/490] Loss (global avg): 0.0723
[Epoch 1 Step 420/490] Loss (global avg): 0.0716
[Epoch 1 Step 430/490] Loss (global avg): 0.0715
[Epoch 1 Step 440/490] Loss (global avg): 0.0713
[Epoch 1 Step 450/490] Loss (global avg): 0.0712
[Epoch 1 Step 460/490] Loss (global avg): 0.0708
[Epoch 1 Step 470/490] Loss (global avg): 0.0707
[Epoch 1 Step 480/490] Loss (global avg): 0.0703
[Eval] Loss (global avg): 0.0889
[Epoch 1] train_loss=0.0705, val_loss=0.0889, epoch_time=732.1s, time/step=1.4941s, samples/s_per_gpu=0.7, samples/s_global=2.7, peak_mem_gb_rank0=33.28
[FSDP] Logged epoch metrics to /pscratch/sd/r/rs2531/Course_Project/FSDP/fsdp_ws4/checkpoints/metrics_epoch.jsonl
========== Epoch 2 ==========
[Epoch 2 Step 0/490] Loss (global avg): 0.0305
[Epoch 2 Step 10/490] Loss (global avg): 0.0624
[Epoch 2 Step 20/490] Loss (global avg): 0.0617
[Epoch 2 Step 30/490] Loss (global avg): 0.0628
[Epoch 2 Step 40/490] Loss (global avg): 0.0565
[Epoch 2 Step 50/490] Loss (global avg): 0.0538
[Epoch 2 Step 60/490] Loss (global avg): 0.0525
[Epoch 2 Step 70/490] Loss (global avg): 0.0502
[Epoch 2 Step 80/490] Loss (global avg): 0.0500
[Epoch 2 Step 90/490] Loss (global avg): 0.0500
[Epoch 2 Step 100/490] Loss (global avg): 0.0491
[Epoch 2 Step 110/490] Loss (global avg): 0.0489
[Epoch 2 Step 120/490] Loss (global avg): 0.0474
[Epoch 2 Step 130/490] Loss (global avg): 0.0477
[Epoch 2 Step 140/490] Loss (global avg): 0.0477
[Epoch 2 Step 150/490] Loss (global avg): 0.0469
[Epoch 2 Step 160/490] Loss (global avg): 0.0467
[Epoch 2 Step 170/490] Loss (global avg): 0.0493
[Epoch 2 Step 180/490] Loss (global avg): 0.0496
[Epoch 2 Step 190/490] Loss (global avg): 0.0496
[Epoch 2 Step 200/490] Loss (global avg): 0.0489
[Epoch 2 Step 210/490] Loss (global avg): 0.0493
[Epoch 2 Step 220/490] Loss (global avg): 0.0488
[Epoch 2 Step 230/490] Loss (global avg): 0.0480
[Epoch 2 Step 240/490] Loss (global avg): 0.0488
[Epoch 2 Step 250/490] Loss (global avg): 0.0485
[Epoch 2 Step 260/490] Loss (global avg): 0.0482
[Epoch 2 Step 270/490] Loss (global avg): 0.0479
[Epoch 2 Step 280/490] Loss (global avg): 0.0492
[Epoch 2 Step 290/490] Loss (global avg): 0.0493
[Epoch 2 Step 300/490] Loss (global avg): 0.0491
[Epoch 2 Step 310/490] Loss (global avg): 0.0489
[Epoch 2 Step 320/490] Loss (global avg): 0.0486
[Epoch 2 Step 330/490] Loss (global avg): 0.0482
[Epoch 2 Step 340/490] Loss (global avg): 0.0474
[Epoch 2 Step 350/490] Loss (global avg): 0.0476
[Epoch 2 Step 360/490] Loss (global avg): 0.0476
[Epoch 2 Step 370/490] Loss (global avg): 0.0476
[Epoch 2 Step 380/490] Loss (global avg): 0.0474
[Epoch 2 Step 390/490] Loss (global avg): 0.0479
[Epoch 2 Step 400/490] Loss (global avg): 0.0487
[Epoch 2 Step 410/490] Loss (global avg): 0.0487
[Epoch 2 Step 420/490] Loss (global avg): 0.0485
[Epoch 2 Step 430/490] Loss (global avg): 0.0483
[Epoch 2 Step 440/490] Loss (global avg): 0.0483
[Epoch 2 Step 450/490] Loss (global avg): 0.0481
[Epoch 2 Step 460/490] Loss (global avg): 0.0483
[Epoch 2 Step 470/490] Loss (global avg): 0.0479
[Epoch 2 Step 480/490] Loss (global avg): 0.0476
[Eval] Loss (global avg): 0.1024
[Epoch 2] train_loss=0.0478, val_loss=0.1024, epoch_time=725.7s, time/step=1.4811s, samples/s_per_gpu=0.7, samples/s_global=2.7, peak_mem_gb_rank0=33.28
[FSDP] Logged epoch metrics to /pscratch/sd/r/rs2531/Course_Project/FSDP/fsdp_ws4/checkpoints/metrics_epoch.jsonl
========== Epoch 3 ==========
[Epoch 3 Step 0/490] Loss (global avg): 0.0553
[Epoch 3 Step 10/490] Loss (global avg): 0.0415
[Epoch 3 Step 20/490] Loss (global avg): 0.0402
[Epoch 3 Step 30/490] Loss (global avg): 0.0383
[Epoch 3 Step 40/490] Loss (global avg): 0.0379
[Epoch 3 Step 50/490] Loss (global avg): 0.0379
[Epoch 3 Step 60/490] Loss (global avg): 0.0372
[Epoch 3 Step 70/490] Loss (global avg): 0.0387
[Epoch 3 Step 80/490] Loss (global avg): 0.0402
[Epoch 3 Step 90/490] Loss (global avg): 0.0403
[Epoch 3 Step 100/490] Loss (global avg): 0.0396
[Epoch 3 Step 110/490] Loss (global avg): 0.0409
[Epoch 3 Step 120/490] Loss (global avg): 0.0403
[Epoch 3 Step 130/490] Loss (global avg): 0.0404
[Epoch 3 Step 140/490] Loss (global avg): 0.0405
[Epoch 3 Step 150/490] Loss (global avg): 0.0409
[Epoch 3 Step 160/490] Loss (global avg): 0.0404
[Epoch 3 Step 170/490] Loss (global avg): 0.0410
[Epoch 3 Step 180/490] Loss (global avg): 0.0415
[Epoch 3 Step 190/490] Loss (global avg): 0.0416
[Epoch 3 Step 200/490] Loss (global avg): 0.0410
[Epoch 3 Step 210/490] Loss (global avg): 0.0403
[Epoch 3 Step 220/490] Loss (global avg): 0.0394
[Epoch 3 Step 230/490] Loss (global avg): 0.0389
[Epoch 3 Step 240/490] Loss (global avg): 0.0393
[Epoch 3 Step 250/490] Loss (global avg): 0.0392
[Epoch 3 Step 260/490] Loss (global avg): 0.0390
[Epoch 3 Step 270/490] Loss (global avg): 0.0389
[Epoch 3 Step 280/490] Loss (global avg): 0.0383
[Epoch 3 Step 290/490] Loss (global avg): 0.0380
[Epoch 3 Step 300/490] Loss (global avg): 0.0376
[Epoch 3 Step 310/490] Loss (global avg): 0.0375
[Epoch 3 Step 320/490] Loss (global avg): 0.0378
[Epoch 3 Step 330/490] Loss (global avg): 0.0388
[Epoch 3 Step 340/490] Loss (global avg): 0.0392
[Epoch 3 Step 350/490] Loss (global avg): 0.0389
[Epoch 3 Step 360/490] Loss (global avg): 0.0389
[Epoch 3 Step 370/490] Loss (global avg): 0.0395
[Epoch 3 Step 380/490] Loss (global avg): 0.0397
[Epoch 3 Step 390/490] Loss (global avg): 0.0397
[Epoch 3 Step 400/490] Loss (global avg): 0.0395
[Epoch 3 Step 410/490] Loss (global avg): 0.0394
[Epoch 3 Step 420/490] Loss (global avg): 0.0391
[Epoch 3 Step 430/490] Loss (global avg): 0.0386
[Epoch 3 Step 440/490] Loss (global avg): 0.0385
[Epoch 3 Step 450/490] Loss (global avg): 0.0385
[Epoch 3 Step 460/490] Loss (global avg): 0.0391
[Epoch 3 Step 470/490] Loss (global avg): 0.0391
[Epoch 3 Step 480/490] Loss (global avg): 0.0389
[Eval] Loss (global avg): 0.0347
[Epoch 3] train_loss=0.0388, val_loss=0.0347, epoch_time=730.2s, time/step=1.4902s, samples/s_per_gpu=0.7, samples/s_global=2.7, peak_mem_gb_rank0=33.28
[FSDP] Logged epoch metrics to /pscratch/sd/r/rs2531/Course_Project/FSDP/fsdp_ws4/checkpoints/metrics_epoch.jsonl
========== Epoch 4 ==========
[Epoch 4 Step 0/490] Loss (global avg): 0.0384
[Epoch 4 Step 10/490] Loss (global avg): 0.0484
[Epoch 4 Step 20/490] Loss (global avg): 0.0508
[Epoch 4 Step 30/490] Loss (global avg): 0.0475
[Epoch 4 Step 40/490] Loss (global avg): 0.0427
[Epoch 4 Step 50/490] Loss (global avg): 0.0391
[Epoch 4 Step 60/490] Loss (global avg): 0.0388
[Epoch 4 Step 70/490] Loss (global avg): 0.0357
[Epoch 4 Step 80/490] Loss (global avg): 0.0364
[Epoch 4 Step 90/490] Loss (global avg): 0.0349
[Epoch 4 Step 100/490] Loss (global avg): 0.0333
[Epoch 4 Step 110/490] Loss (global avg): 0.0325
[Epoch 4 Step 120/490] Loss (global avg): 0.0320
[Epoch 4 Step 130/490] Loss (global avg): 0.0312
[Epoch 4 Step 140/490] Loss (global avg): 0.0302
[Epoch 4 Step 150/490] Loss (global avg): 0.0308
[Epoch 4 Step 160/490] Loss (global avg): 0.0312
[Epoch 4 Step 170/490] Loss (global avg): 0.0320
[Epoch 4 Step 180/490] Loss (global avg): 0.0318
[Epoch 4 Step 190/490] Loss (global avg): 0.0320
[Epoch 4 Step 200/490] Loss (global avg): 0.0323
[Epoch 4 Step 210/490] Loss (global avg): 0.0318
[Epoch 4 Step 220/490] Loss (global avg): 0.0315
[Epoch 4 Step 230/490] Loss (global avg): 0.0319
[Epoch 4 Step 240/490] Loss (global avg): 0.0316
[Epoch 4 Step 250/490] Loss (global avg): 0.0313
[Epoch 4 Step 260/490] Loss (global avg): 0.0313
[Epoch 4 Step 270/490] Loss (global avg): 0.0317
[Epoch 4 Step 280/490] Loss (global avg): 0.0312
[Epoch 4 Step 290/490] Loss (global avg): 0.0310
[Epoch 4 Step 300/490] Loss (global avg): 0.0307
[Epoch 4 Step 310/490] Loss (global avg): 0.0303
[Epoch 4 Step 320/490] Loss (global avg): 0.0300
[Epoch 4 Step 330/490] Loss (global avg): 0.0295
[Epoch 4 Step 340/490] Loss (global avg): 0.0292
[Epoch 4 Step 350/490] Loss (global avg): 0.0292
[Epoch 4 Step 360/490] Loss (global avg): 0.0297
[Epoch 4 Step 370/490] Loss (global avg): 0.0298
[Epoch 4 Step 380/490] Loss (global avg): 0.0303
[Epoch 4 Step 390/490] Loss (global avg): 0.0300
[Epoch 4 Step 400/490] Loss (global avg): 0.0298
[Epoch 4 Step 410/490] Loss (global avg): 0.0297
