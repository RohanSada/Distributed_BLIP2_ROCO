
The following have been reloaded with a version change:
  1) cudatoolkit/12.4 => cudatoolkit/12.9

Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.63it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.49it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.48it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.25it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.64it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.51it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.49it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.26it/s]
/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py:345: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(dtype=autocast_dtype):
/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py:345: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(dtype=autocast_dtype):
/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/apex/_autocast_utils.py:26: FutureWarning: `torch.cuda.amp.autocast_mode._cast(value, dtype)` is deprecated. Please use `torch.amp.autocast_mode._cast(value, 'cuda', dtype)` instead.
  return torch.cuda.amp.autocast_mode._cast(args, torch.get_autocast_gpu_dtype())
/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/apex/_autocast_utils.py:26: FutureWarning: `torch.cuda.amp.autocast_mode._cast(value, dtype)` is deprecated. Please use `torch.amp.autocast_mode._cast(value, 'cuda', dtype)` instead.
  return torch.cuda.amp.autocast_mode._cast(args, torch.get_autocast_gpu_dtype())
[rank1]: Traceback (most recent call last):
[rank1]:   File "/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py", line 710, in <module>
[rank1]:     main()
[rank1]:   File "/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py", line 658, in main
[rank1]:     train_metrics = train_one_epoch(
[rank1]:                     ^^^^^^^^^^^^^^^^
[rank1]:   File "/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py", line 358, in train_one_epoch
[rank1]:     loss.backward()
[rank1]:   File "/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/torch/_tensor.py", line 647, in backward
[rank1]:     torch.autograd.backward(
[rank1]:   File "/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
[rank1]:     _engine_run_backward(
[rank1]:   File "/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.34 GiB. GPU 1 has a total capacity of 39.38 GiB of which 962.12 MiB is free. Including non-PyTorch memory, this process has 38.43 GiB memory in use. Of the allocated memory 36.81 GiB is allocated by PyTorch, and 878.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py", line 710, in <module>
[rank0]:     main()
[rank0]:   File "/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py", line 658, in main
[rank0]:     train_metrics = train_one_epoch(
[rank0]:                     ^^^^^^^^^^^^^^^^
[rank0]:   File "/pscratch/sd/r/rs2531/Course_Project/FSDP/train_fsdp.py", line 358, in train_one_epoch
[rank0]:     loss.backward()
[rank0]:   File "/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/torch/_tensor.py", line 647, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/global/common/software/nersc9/pytorch/2.8.0/lib/python3.12/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.34 GiB. GPU 0 has a total capacity of 39.38 GiB of which 688.12 MiB is free. Including non-PyTorch memory, this process has 38.70 GiB memory in use. Of the allocated memory 36.98 GiB is allocated by PyTorch, and 978.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
srun: error: nid002956: task 1: Exited with exit code 1
srun: Terminating StepId=45859004.0
srun: error: nid002956: task 0: Exited with exit code 1
